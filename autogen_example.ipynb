{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5385e068-ecb9-420b-b66a-7f5fa672e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "from autogen_core import AgentId, MessageContext, RoutedAgent, SingleThreadedAgentRuntime, message_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd775fc4-b7b2-43d4-9b89-6d84c7f3f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Check if variables are correctly loaded from .env\n",
    "api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    raise ValueError(\"AZURE_OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "DEPLOYMENT_NAME = os.getenv('DEPLOYMENT_NAME')\n",
    "if not DEPLOYMENT_NAME:\n",
    "    raise ValueError(\"DEPLOYMENT_NAME not found in environment variables\")\n",
    "\n",
    "API_VERSION = os.getenv('API_VERSION')\n",
    "if not DEPLOYMENT_NAME:\n",
    "    raise ValueError(\"API_VERSION not found in environment variables\")\n",
    "    \n",
    "AZURE_ENDPOINT = os.getenv('AZURE_ENDPOINT')\n",
    "if not AZURE_ENDPOINT:\n",
    "    raise ValueError(\"AZURE_ENDPOINT not found in environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9e0186f-d95c-41b3-81d1-eacbf9b3ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LLM model\n",
    "llm = AzureChatOpenAI(\n",
    "    temperature = 0,\n",
    "    model_name = \"gpt-4o\",\n",
    "    deployment_name = DEPLOYMENT_NAME,  \n",
    "    api_version = API_VERSION,\n",
    "    azure_endpoint = AZURE_ENDPOINT\n",
    ")\n",
    "\n",
    "### Statefully manage chat history ###\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "store = {} # This dictionary will retain all chat history\n",
    "        \n",
    "# Load company data \n",
    "path_json_company = 'data/json_company.json'\n",
    "with open(path_json_company, 'r', encoding='utf-8') as file:\n",
    "    json_company = json.load(file)\n",
    "\n",
    "# Load client data \n",
    "path_json_client = 'data/json_client.json'\n",
    "with open(path_json_client, 'r', encoding='utf-8') as file:\n",
    "    json_client = json.load(file)\n",
    "\n",
    "# This class is essential for Autogen, but additional attributes can be added if necessary.\n",
    "@dataclass\n",
    "class Message:\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be04502-9ded-469e-aa6d-f4e4ec45b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent to collect information about the company\n",
    "# The purpose of this agent is to return relevant information in a given format, so it can be used in, for example, a SQL command.\n",
    "# The user will not see this agent's response, so we do not need to consider the agent's personality.\n",
    "system_template_company = \"\"\" \n",
    "You are specialized in internal queries.\n",
    "You have access to a set of internal information.\n",
    "When receiving a question from a user, select which of this information is relevant.\n",
    "Return the names of all relevant keys separated by commas, along with their probabilities separated by ':'. Try to select at least 3 topics.\n",
    "If no information is relevant, return 'default.'\n",
    "\n",
    "User question:\n",
    "{user_question}\n",
    "\n",
    "Available information:\n",
    "- company_history: History of your company describing the history of {company_name}.\n",
    "- location: Location of {company_name}'s branches.\n",
    "- mission_statement: Mission of the company {company_name}.\n",
    "- electronics: electronic Products available for sale.\n",
    "- food: Edible products available for sale.\n",
    "- promotions: Current ongoing promotions.\n",
    "\"\"\"\n",
    "\n",
    "# Agent to collect information about the company\n",
    "class CompanyAgent(RoutedAgent):\n",
    "    def __init__(self, description, system_template, llm, json_data):\n",
    "        super().__init__(description) \n",
    "        self.system_template = system_template\n",
    "        self.llm = llm\n",
    "        self.json_data = json_data\n",
    "\n",
    "    @message_handler\n",
    "    async def on_my_message(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        print(\"TESTING: Inside CompanyAgent.\")\n",
    "\n",
    "        # Set LLM\n",
    "        company_name = self.json_data[\"company_name\"]\n",
    "        system_prompt = ChatPromptTemplate.from_template(self.system_template) \n",
    "        chain_company = system_prompt | self.llm\n",
    "        answer_chain_company = chain_company.invoke(\n",
    "            {\n",
    "                'company_name': company_name,\n",
    "                'user_question': message.content,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"TESTING: answer_chain_company: {answer_chain_company.content}.\")\n",
    "        \n",
    "        # Get relevant information from json\n",
    "        relevant_information = \"\"\n",
    "        for e in answer_chain_company.content.split(','):\n",
    "            e_2 = e.split(':')\n",
    "            if e_2[0].strip() in ['electronics', 'food']:\n",
    "                relevant_information += \"\\n\"+ self.json_data['available_products'][e_2[0].strip()]\n",
    "            else:\n",
    "                value = self.json_data[e_2[0].strip()]\n",
    "                if value is not None and (len(value) > 0):\n",
    "                    relevant_information += \"\\n\"+ value\n",
    "\n",
    "        print(f\"TESTING: relevant_information: {relevant_information}.\")\n",
    "        \n",
    "        print('-----------------------------------------------------------------------')\n",
    "        print()\n",
    "        return Message(content = relevant_information)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb1e503e-1c1e-4105-93a8-75a0f2264ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent to collect information about the company\n",
    "# The purpose of this agent is to return relevant information in a given format, so it can be used in, for example, a SQL command.\n",
    "# The user will not see this agent's response, so we do not need to consider the agent's personality.\n",
    "# We can add as many agent as we want. \n",
    "system_template_client = \"\"\" \n",
    "You are specialized in queries.\n",
    "You have access to a set of information.\n",
    "When receiving a question from a user, select which of this information is relevant.\n",
    "Return the names of all relevant keys separated by commas, along with their probabilities separated by ':'. Try to select at least 3 topics.\n",
    "If no information is relevant, return 'default.'\n",
    "\n",
    "User question:\n",
    "{user_question}\n",
    "\n",
    "Available information:\n",
    "- address: Address of {client_name}.\n",
    "- last_purchase_date: Last purchase date of {client_name}.\n",
    "- last_purchase: Last purchase of {client_name}.\n",
    "\"\"\"\n",
    "\n",
    "# Agent to collect information about the client\n",
    "class ClientAgent(RoutedAgent):\n",
    "    def __init__(self, description, system_template, llm, json_data):\n",
    "        super().__init__(description)  \n",
    "        self.system_template = system_template\n",
    "        self.llm = llm\n",
    "        self.json_data = json_data\n",
    "\n",
    "    @message_handler\n",
    "    async def on_my_message(self, message: Message, ctx: MessageContext) -> Message:\n",
    "\n",
    "        print(\"TESTING: Inside ClientAgent.\")\n",
    "\n",
    "        # Set LLM\n",
    "        client_name = self.json_data[\"client_name\"]\n",
    "        system_prompt = ChatPromptTemplate.from_template(self.system_template)\n",
    "        chain_client = system_prompt | self.llm\n",
    "        answer_chain_client = chain_client.invoke(\n",
    "            {\n",
    "                'client_name': client_name,\n",
    "                'user_question': message.content,\n",
    "            }\n",
    "        )\n",
    "        print(f\"TESTING: answer_chain_client: {answer_chain_client.content}.\")\n",
    "\n",
    "        # Get relevant information from json\n",
    "        relevant_information = \"\"\n",
    "        for e in answer_chain_client.content.split(','):\n",
    "            e_2 = e.split(':')\n",
    "            value = self.json_data[e_2[0].strip()]\n",
    "            if value is not None and (len(value) > 0):\n",
    "                relevant_information += \"\\n\"+ value\n",
    "\n",
    "        print(f\"TESTING: relevant_information: {relevant_information}.\")\n",
    "        print('-----------------------------------------------------------------------')\n",
    "        print()\n",
    "        return Message(content=relevant_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c93be70-784c-4d64-9228-3920f7a91c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the agent that will communicate directly with the user.\n",
    "# Here, we need to consolidate all the information returned by the other agents.\n",
    "# Additionally, it is crucial to assign a personality to this agent.\n",
    "\n",
    "system_template_OuterAgent = \"\"\" \n",
    "You are the helpful virtual assistent VirtAssist working for {company_name}.\n",
    "You always answer {client_name} questions received using the tones: {company_tone}.\n",
    "To answer the user question, you take into account company information and the user information.\n",
    "\n",
    "Company information:\n",
    "{response_company}\n",
    "\n",
    "User information:\n",
    "{response_client}\n",
    "\n",
    "User question:\n",
    "{user_question}\n",
    "\"\"\"\n",
    "# Outer Agent\n",
    "class OuterAgent(RoutedAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        description,\n",
    "        llm,\n",
    "        session_id,\n",
    "        system_template,\n",
    "        company_agent_id,\n",
    "        client_agent_id,\n",
    "        json_company,\n",
    "        json_client,\n",
    "    ):\n",
    "        super().__init__(description)\n",
    "        self.llm = llm\n",
    "        self.session_id = session_id\n",
    "        self.system_template = system_template\n",
    "        self.company_agent_id = AgentId(company_agent_id, self.id.key)\n",
    "        self.client_agent_id = AgentId(client_agent_id, self.id.key)\n",
    "        self.json_company = json_company\n",
    "        self.json_client = json_client\n",
    "\n",
    "    @message_handler\n",
    "    async def on_my_message(self, message: Message, ctx: MessageContext) -> Message:\n",
    "\n",
    "        print(\"TESTING: Inside OuterAgent.\")\n",
    "\n",
    "        # Get information from other agents\n",
    "        response_company = await self.send_message(message, self.company_agent_id)\n",
    "        response_client = await self.send_message(message, self.client_agent_id)\n",
    "\n",
    "        # Set LLM \n",
    "        company_name = self.json_company[\"company_name\"]\n",
    "        company_tone = self.json_company.get(\"tone\", \"neutral\")\n",
    "        client_name = self.json_client[\"client_name\"]\n",
    "        # Use this to run chat without history\n",
    "        # system_prompt = ChatPromptTemplate.from_template(self.system_template)\n",
    "        # # Create a chain for question rewriting\n",
    "        # chain_OuterAgent = system_prompt | self.llm\n",
    "        \n",
    "        # answer_chain_OuterAgent = chain_OuterAgent.invoke(\n",
    "        #     {\n",
    "        #         'company_name': company_name,\n",
    "        #         'company_tone': company_tone,\n",
    "        #         'client_name': client_name,\n",
    "        #         \"response_company\": response_company,\n",
    "        #         \"response_client\": response_client,\n",
    "        #         'user_question': message.content,\n",
    "        #     }\n",
    "        # )\n",
    "\n",
    "        # Use this to add chat history\n",
    "        system_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", self.system_template),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"{user_question}\"),\n",
    "        ])\n",
    "        chain_OuterAgent = system_prompt | self.llm\n",
    "        ### Statefully manage chat history ###\n",
    "        conversational_chain_OuterAgent = RunnableWithMessageHistory(\n",
    "            chain_OuterAgent,\n",
    "            get_session_history,\n",
    "            input_messages_key=\"user_question\",\n",
    "            history_messages_key=\"chat_history\",\n",
    "        )\n",
    "\n",
    "        answer_chain_OuterAgent = conversational_chain_OuterAgent.invoke(\n",
    "            {\n",
    "                # Variables used in prompt\n",
    "                'company_name': company_name,\n",
    "                'company_tone': company_tone,\n",
    "                'client_name': client_name,\n",
    "                \"response_company\": response_company,\n",
    "                \"response_client\": response_client,\n",
    "                'user_question': message.content, \n",
    "            },\n",
    "            config={\n",
    "                \"configurable\": {\"session_id\": self.session_id}\n",
    "            },  # constructs a key \"session_id\" in `store`.\n",
    "        ) \n",
    "\n",
    "        print(f\"TESTING: answer_chain_OuterAgent: {answer_chain_OuterAgent.content}\")\n",
    "        print('-----------------------------------------------------------------------')\n",
    "        print()\n",
    "        return Message(content=answer_chain_OuterAgent.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba6bd44-dd14-4e72-a165-07357ea0020f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING: Inside OuterAgent.\n",
      "TESTING: Inside CompanyAgent.\n",
      "TESTING: answer_chain_company: electronics:0.3, food:0.3, promotions:0.4.\n",
      "TESTING: relevant_information: \n",
      "Available products - TV: 100; Laptops: 400\n",
      "Available products - Chocolate: 600, Meet: 200\n",
      "Promotion of the day: Buy 1 chocolate, receive 3..\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "TESTING: Inside ClientAgent.\n",
      "TESTING: answer_chain_client: last_purchase_date:0.3, last_purchase:0.5, address:0.2.\n",
      "TESTING: relevant_information: \n",
      "Last purchase date: 30 days ago\n",
      "Last purchase: 30 chocolates\n",
      "address: SÃ£o Paulo.\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "TESTING: answer_chain_OuterAgent: Well, Bob, considering your last purchase was a whopping 30 chocolates and itâ€™s been 30 days since then, Iâ€™d say itâ€™s time to restock your sweet stash! Plus, with todayâ€™s promotion, you buy 1 chocolate and get 3 more! Itâ€™s like a chocolate party waiting to happen. ğŸ‰ğŸ«\n",
      "\n",
      "But hey, if youâ€™re feeling tech-savvy, weâ€™ve got TVs and laptops too. Just imagine watching your favorite shows on a new TV while munching on all that chocolate. Sounds like a plan, right? ğŸ˜„ğŸ“ºğŸ«\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "TESTING: Inside OuterAgent.\n",
      "TESTING: Inside CompanyAgent.\n",
      "TESTING: answer_chain_company: default.\n",
      "TESTING: relevant_information: .\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "TESTING: Inside ClientAgent.\n",
      "TESTING: answer_chain_client: default.\n",
      "TESTING: relevant_information: .\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "TESTING: answer_chain_OuterAgent: Oh, Bob, you know the best kind of party is a chocolate party! ğŸ‰ğŸ« But if youâ€™re looking for something a bit more... lively, how about a tech party? Imagine unboxing the latest gadgets, setting up your new TV, and maybe even throwing in a new sound system for good measure. Itâ€™s like a rave, but with less dancing and more unwrapping. ğŸ•ºğŸ“¦\n",
      "\n",
      "So, whatâ€™s it gonna be? Chocolate or tech? Or both? Because why not have the best of both worlds! ğŸ˜„\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "TESTING: Inside OuterAgent.\n",
      "TESTING: Inside CompanyAgent.\n",
      "TESTING: answer_chain_company: default.\n",
      "TESTING: relevant_information: .\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "TESTING: Inside ClientAgent.\n",
      "TESTING: answer_chain_client: default.\n",
      "TESTING: relevant_information: .\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "TESTING: answer_chain_OuterAgent: Ah, Bob, I asked you to imagine the ultimate combo: a chocolate party and a tech party! ğŸ‰ğŸ«ğŸ“º Picture this: you, surrounded by a mountain of chocolates, unwrapping the latest gadgets, and setting up your new TV. Itâ€™s like Christmas morning, but with more sugar and fewer carols. ğŸ˜„\n",
      "\n",
      "So, are you ready to dive into this sweet and techy dream? Or do you need more convincing? Because Iâ€™ve got plenty of imagination to spare! ğŸ˜‰\n",
      "-----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initializes a runtime environment for multiple agents, registers them, and starts the runtime.\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "await CompanyAgent.register(runtime, \"company_agent\", lambda: CompanyAgent(\n",
    "    description=\"CompanyAgent\",\n",
    "    system_template=system_template_company,\n",
    "    llm=llm,\n",
    "    json_data=json_company\n",
    "))\n",
    "await ClientAgent.register(runtime, \"client_agent\", lambda: ClientAgent(\n",
    "    description=\"ClientAgent\",\n",
    "    system_template=system_template_client,\n",
    "    llm=llm,\n",
    "    json_data=json_client\n",
    "))\n",
    "await OuterAgent.register(\n",
    "    runtime,\n",
    "    \"outer_agent\",\n",
    "    lambda: OuterAgent(\n",
    "        description=\"OuterAgent\",\n",
    "        llm=llm,\n",
    "        session_id = 'Teste_01',\n",
    "        system_template=system_template_OuterAgent,\n",
    "        company_agent_id=\"company_agent\",\n",
    "        client_agent_id=\"client_agent\",\n",
    "        json_company=json_company,\n",
    "        json_client=json_client,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# The runtime.start() command launches the runtime, enabling the agents to function and interact as intended.\n",
    "runtime.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7015faf2-457d-44e3-a607-e156ba716a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final response: Well, Bob, considering your last purchase was a whopping 30 chocolates and itâ€™s been 30 days since then, Iâ€™d say itâ€™s time to restock your sweet stash! Plus, with todayâ€™s promotion, you buy 1 chocolate and get 3 more! Itâ€™s like a chocolate party waiting to happen. ğŸ‰ğŸ«\n",
      "\n",
      "But hey, if youâ€™re feeling tech-savvy, weâ€™ve got TVs and laptops too. Just imagine watching your favorite shows on a new TV while munching on all that chocolate. Sounds like a plan, right? ğŸ˜„ğŸ“ºğŸ«\n"
     ]
    }
   ],
   "source": [
    "# Send and receive a message\n",
    "# Give an id for the agent that will communicate with the user\n",
    "outer_agent_id = AgentId(\"outer_agent\", \"default\")\n",
    "\n",
    "# Send message to chat\n",
    "user_message = \"What should I buy?\"\n",
    "response = await runtime.send_message(Message(content=user_message), outer_agent_id)\n",
    "\n",
    "print(f\"Final response: {response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbcc4f5f-69a3-47f4-8c0e-04b37d09b566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, Bob, you know the best kind of party is a chocolate party! ğŸ‰ğŸ« But if youâ€™re looking for something a bit more... lively, how about a tech party? Imagine unboxing the latest gadgets, setting up your new TV, and maybe even throwing in a new sound system for good measure. Itâ€™s like a rave, but with less dancing and more unwrapping. ğŸ•ºğŸ“¦\n",
      "\n",
      "So, whatâ€™s it gonna be? Chocolate or tech? Or both? Because why not have the best of both worlds! ğŸ˜„\n"
     ]
    }
   ],
   "source": [
    "# Test chat history\n",
    "# Send message to chat\n",
    "user_message = \"What party did you say?\"\n",
    "response = await runtime.send_message(Message(content=user_message), outer_agent_id)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46289ca7-78db-4e28-b9dc-cce738b2f9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, Bob, I asked you to imagine the ultimate combo: a chocolate party and a tech party! ğŸ‰ğŸ«ğŸ“º Picture this: you, surrounded by a mountain of chocolates, unwrapping the latest gadgets, and setting up your new TV. Itâ€™s like Christmas morning, but with more sugar and fewer carols. ğŸ˜„\n",
      "\n",
      "So, are you ready to dive into this sweet and techy dream? Or do you need more convincing? Because Iâ€™ve got plenty of imagination to spare! ğŸ˜‰\n"
     ]
    }
   ],
   "source": [
    "# Test chat history\n",
    "# Send message to chat\n",
    "user_message = \"What did you asked me to imagine?\"\n",
    "response = await runtime.send_message(Message(content=user_message), outer_agent_id)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d1381-05bc-4ff3-9625-2ba04ed6dba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478bf71d-ce37-41f1-b203-60d2af4f8525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80ef5525-ad93-473b-b7d6-8f236e913480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop execution once it becomes idle, meaning when all tasks or agents within the runtime have completed their work and there is nothing left to process.\n",
    "await runtime.stop_when_idle()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
